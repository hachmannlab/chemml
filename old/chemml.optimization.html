

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Optimization module &mdash; ChemML  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Visualization module" href="chemml.visualization.html" />
    <link rel="prev" title="Models module" href="chemml.models.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> ChemML
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">ChemML Wrapper documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="CMLWTutorial.html">ChemML Wrapper Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="CMLWInputFile.html">Input File Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="CMLWInputFileGenerator.html">Input File GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="CMLWContentsTable.html">Table of Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="CMLWReference.html">Wrapper Reference</a></li>
</ul>
<p class="caption"><span class="caption-text">ChemML library Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Molecule.html">Molecule</a></li>
<li class="toctree-l1"><a class="reference internal" href="active_model_based.html">Active Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="ga_hyper_opt.html">Hyperparameter Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="ga_feature_selection.html">Feature Selection</a></li>
</ul>
<p class="caption"><span class="caption-text">ChemML library documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="chemml.chem.html">Chem module</a></li>
<li class="toctree-l1"><a class="reference internal" href="chemml.chem.magpie_python.html">Magpie_Python module</a></li>
<li class="toctree-l1"><a class="reference internal" href="chemml.initialization.html">Initialization module</a></li>
<li class="toctree-l1"><a class="reference internal" href="chemml.datasets.html">Datasets module</a></li>
<li class="toctree-l1"><a class="reference internal" href="chemml.preprocessing.html">Preprocessing module</a></li>
<li class="toctree-l1"><a class="reference internal" href="chemml.models.html">Models module</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Optimization module</a></li>
<li class="toctree-l1"><a class="reference internal" href="chemml.visualization.html">Visualization module</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ChemML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Optimization module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/chemml.optimization.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="optimization-module">
<h1>Optimization module<a class="headerlink" href="#optimization-module" title="Permalink to this headline">¶</a></h1>
<span class="target" id="module-chemml.optimization"></span><dl class="simple">
<dt>The cheml.optimization module includes (please click on links adjacent to function names for more information):</dt><dd><ul class="simple">
<li><p>GeneticAlgorithm: <a class="reference internal" href="#chemml.optimization.GeneticAlgorithm" title="chemml.optimization.GeneticAlgorithm"><code class="xref py py-func docutils literal notranslate"><span class="pre">GeneticAlgorithm()</span></code></a></p></li>
<li><p>ActiveLearning: <a class="reference internal" href="#chemml.optimization.ActiveLearning" title="chemml.optimization.ActiveLearning"><code class="xref py py-func docutils literal notranslate"><span class="pre">ActiveLearning()</span></code></a></p></li>
</ul>
</dd>
</dl>
<dl class="class">
<dt id="chemml.optimization.GeneticAlgorithm">
<em class="property">class </em><code class="sig-prename descclassname">chemml.optimization.</code><code class="sig-name descname">GeneticAlgorithm</code><span class="sig-paren">(</span><em class="sig-param">evaluate</em>, <em class="sig-param">space</em>, <em class="sig-param">fitness=('Max'</em>, <em class="sig-param">)</em>, <em class="sig-param">pop_size=50</em>, <em class="sig-param">crossover_size=30</em>, <em class="sig-param">mutation_size=20</em>, <em class="sig-param">crossover_type='Blend'</em>, <em class="sig-param">fused_cutoff=5</em>, <em class="sig-param">mutation_prob=0.6</em>, <em class="sig-param">algorithm=3</em>, <em class="sig-param">initial_population=None</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.GeneticAlgorithm" title="Permalink to this definition">¶</a></dt>
<dd><p>A python implementation of real-valued, genetic algorithm for solving optimization problems.</p>
<dl>
<dt>evaluate: function</dt><dd><p>The objective function that has to be optimized. The first parameter of the objective function is a list of the trial values of the hyper-parameters in the order in which they are declared in the space variable. The objective function should always return a tuple with the metric/metrics for single/multi-objective optimization.</p>
</dd>
<dt>space: tuple, </dt><dd><p>A tuple of dict objects specifying the hyper-parameter space to search in. 
Each hyper-parameter should be a python dict object with the name of the hyper-parameter as the key. 
Value is also a dict object with one mandatory key among: ‘uniform’, ‘int’ and ‘choice’ for defining floating point, integer and choice variables respectively. 
Values for these keys should be a list defining the valid hyper-parameter search space (lower and upper bounds for ‘int’ and ‘uniform’, and all valid choices for ‘choice’). 
For uniform, a ‘mutation’ key is also required for which the value is [mean, standard deviation] for the gaussian distribution.
Example:</p>
<blockquote>
<div><dl class="simple">
<dt>({‘alpha’: {‘uniform’: [0.001, 1], </dt><dd><p>‘mutation’: [0, 1]}},</p>
</dd>
</dl>
<p>{‘layers’: {‘int’: [1, 3]}},
{‘neurons’: {‘choice’: range(0,200,20)}})</p>
</div></blockquote>
</dd>
<dt>fitness: tuple, optional (default = (‘Max’,)</dt><dd><p>A tuple of string(s) for Maximizing (Max) or minimizing (Min) the objective function(s).</p>
</dd>
<dt>pop_size: integer, optional (default = 50)</dt><dd><p>Size of the population</p>
</dd>
<dt>crossover_size: int, optional (default = 30)</dt><dd><p>Number of individuals to select for crossover.</p>
</dd>
<dt>mutation_size: int, optional (default = 20)</dt><dd><p>Number of individuals to select for mutation.</p>
</dd>
<dt>crossover_type: string, optional (default = “Blend”)</dt><dd><p>Type of crossover: SinglePoint, DoublePoint, Blend, Uniform</p>
</dd>
<dt>mutation_prob: float, optional (default = 0.4)</dt><dd><p>Probability of mutation.</p>
</dd>
<dt>algorithm: int, optional (default=1)</dt><dd><p>The algorithm to use for the search. Look at the ‘search’ method for a description of the various algorithms.</p>
</dd>
<dt>initial_population: list, optional (default=None)</dt><dd><p>The initial population for the algorithm to start with. If not provided, initial population is randomly generated.</p>
</dd>
</dl>
<dl class="method">
<dt id="chemml.optimization.GeneticAlgorithm.search">
<code class="sig-name descname">search</code><span class="sig-paren">(</span><em class="sig-param">n_generations=20</em>, <em class="sig-param">early_stopping=10</em>, <em class="sig-param">init_ratio=0.35</em>, <em class="sig-param">crossover_ratio=0.35</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.GeneticAlgorithm.search" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Algorithm 1:</dt><dd><p>Initial population is instantiated. 
Roulette wheel selection is used for selecting individuals for crossover and mutation.
The initial population, crossovered and mutated individuals form the pool of individuals from which the best
n members are selected as the initial population for the next generation, where n is the size of population.</p>
</dd>
<dt>Algorithm 2:</dt><dd><p>Same as algorithm 1 but when selecting individuals for next generation, n members are selected using Roulette wheel selection.</p>
</dd>
<dt>Algorithm 3:</dt><dd><p>Same as algorithm 1 but when selecting individuals for next generation, best members from each of the three pools (initital population, crossover and mutation) are selected according to the input parameters in the search method.</p>
</dd>
<dt>Algorithm 4:</dt><dd><p>Same as algorithm 1 but mutation population is selected from the crossover population and not from the parents directly.</p>
</dd>
</dl>
<dl class="simple">
<dt>n_generations: integer, optional (default = 20)</dt><dd><p>An integer for the number of generations to evolve the population for.</p>
</dd>
<dt>early_stopping: int, optional (default=10)</dt><dd><p>Integer specifying the maximum number of generations for which the algorithm can select the same best individual, after which 
the search terminates.</p>
</dd>
<dt>init_ratio: float, optional (default = 0.4)</dt><dd><p>Fraction of initial population to select for next generation. Required only for algorithm 3.</p>
</dd>
<dt>crossover_ratio: float, optional (default = 0.3)</dt><dd><p>Fraction of crossover population to select for next generation. Required only for algorithm 3.</p>
</dd>
</dl>
<dl class="simple">
<dt>population: list,</dt><dd><p>list of individuals from the final generation</p>
</dd>
<dt>fitness_dict: dict,</dt><dd><p>dictionary of all individuals evaluated by the algorithm</p>
</dd>
</dl>
<dl class="simple">
<dt>best_ind_df:  pandas dataframe</dt><dd><p>A pandas dataframe of best individuals of each generation</p>
</dd>
<dt>best_ind:  dict,</dt><dd><p>The best individual after the last generation.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="chemml.optimization.ActiveLearning">
<em class="property">class </em><code class="sig-prename descclassname">chemml.optimization.</code><code class="sig-name descname">ActiveLearning</code><span class="sig-paren">(</span><em class="sig-param">model_creator, U, target_layer, train_size=100, test_size=100, test_type='passive', batch_size=[10], history=2</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.ActiveLearning" title="Permalink to this definition">¶</a></dt>
<dd><p>The implementation of active learning of regression models using BEMCM and QBC methods and approaches for distribution shift alleviations.
This algorithm assumes that you have a pool of unlabeled data points and a limited budget to label them.
Thus, we combine the efficiency of the machine learning models with our active learning approach to suggest
optimal number of calculations to provide labeled data.</p>
<p>The implementation of this algorithm follows an interactive approach.
In other words, we often ask you to provide labels for the selected data points.</p>
<dl>
<dt>model_creator: FunctionType</dt><dd><p>It’s a function that returns the model. We call this function a couple of times during the search to build
fresh models with random weights.
Note that you should also compile your model inside the function. We don’t provide options to compile the model.
The compile (e.g., for Keras models) defines the loss function, the optimizer/learning rate, and the metrics.</p>
</dd>
<dt>U: array-like</dt><dd><p>The features/descriptors of unlabeled candidates that are available to be labeled.</p>
</dd>
<dt>target_layer: str or list or FunctionType</dt><dd><p>If str, it’s the name of a layer of the Keras model that is linearly mapped to the outputs.
If list, it’s a list of str that each element corresponds to the name of layers.
If a function, it should be able to receive a model that will be created using the ‘model_creator’ and the X inputs,
and returns the outputs of the linear layer.</p>
</dd>
<dt>train_size: int, optional (default = 100)</dt><dd><p>It represents the absolute number of train samples that must be selected as the initial training set.
The search will begin with this many training samples and labels are required immediately.
Please choose a number based on:</p>
<blockquote>
<div><ul class="simple">
<li><p>your budget.</p></li>
<li><p>the minumum number that you think is enough to train your model.</p></li>
</ul>
</div></blockquote>
</dd>
<dt>test_size: int, optional (default = 100)</dt><dd><p>It represents the absolute number of test samples that will be held out for the evaluation of the model in all
rounds of your active learning search.
Note the test set will be acquired before search begins and won’t be updated later during search.
Please choose a number based on:</p>
<blockquote>
<div><ul class="simple">
<li><p>your budget.</p></li>
<li><p>the diversity of the pool of candidates (U).</p></li>
</ul>
</div></blockquote>
</dd>
<dt>test_type: str, optional (default = ‘passive’)</dt><dd><p>The value must be either ‘passive’ or ‘active’.
If passive, test set will be sampled randomly at the initialization.
If active, test set will be sampled randomly at each round.</p>
</dd>
<dt>batch_size: list, optional (default = [10])</dt><dd><p>This is a list of maxumum three non-negative int values. Each value specifies the number of data points that
our active learning approaches should query every round. The order of active learning approaches are as follows:</p>
<blockquote>
<div><ul class="simple">
<li><p>Batch Expected Model Change Maximization (BEMCM)</p></li>
<li><p>Query By Committee (QBC)</p></li>
<li><p>Distribution Shift Alleviation (DSA)</p></li>
</ul>
</div></blockquote>
<p>Note that the last method (i.e., DSA) is a complement to the first two methods and can not be specified alone.</p>
</dd>
<dt>history: int, optional (default = 2)</dt><dd><p>This parameter must be an integer and greater than one. It specifies the number of previous active learning
rounds to memorize for the distribution shift alleviation (DSA) approach.</p>
</dd>
</dl>
<dl>
<dt>queries: list</dt><dd><p>This list provides information regarding the indices of queried candidates.
for each element of the list:</p>
<blockquote>
<div><ul class="simple">
<li><p>The index-0 is a short description.</p></li>
<li><p>The index-1 is an array of indices.</p></li>
</ul>
</div></blockquote>
</dd>
<dt>query_number: int</dt><dd><p>The number of rounds you have run the active learning search method.</p>
</dd>
<dt>U_indices: ndarray</dt><dd><p>This is an array of the remaining unlabeled indices.</p>
</dd>
<dt>train_indices: ndarray</dt><dd><p>This is an array of all candidates’ indices that are used as the training data.</p>
</dd>
<dt>test_indices: ndarray</dt><dd><p>This is an array of all candidates’ indices that are used as the test data.</p>
</dd>
<dt>Y_pred: ndarray</dt><dd><p>The predicted Y values at the current stage. These values will be updated after each run of <cite>search</cite> method.</p>
</dd>
<dt>results: pandas.DataFrame</dt><dd><p>The final results of the active learning approach.</p>
</dd>
<dt>random_results: pandas.DataFrame</dt><dd><p>The final results of the random search.</p>
</dd>
</dl>
<p>initialize
deposit
search
random_search
visualize
get_target_layer</p>
<ul class="simple">
<li><p>You won’t be able to resume the search unless you deposit the requested labeled data.</p></li>
</ul>
<dl class="method">
<dt id="chemml.optimization.ActiveLearning.deposit">
<code class="sig-name descname">deposit</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">Y</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.ActiveLearning.deposit" title="Permalink to this definition">¶</a></dt>
<dd><p>This function helps you to deposit the data for candidates that were queried by initialize or search functions.</p>
<dl class="simple">
<dt>indices: ndarray or list or tuple</dt><dd><p>A 1-dimensional array of indices that was queried by initialize or search methods.
You can deposit the data partially and it doesn’t have to be the entire array that is queried.</p>
</dd>
<dt>Y: array-like</dt><dd><p>The 2-dimensional labels of the data points as it will be used for the training of the model.
The first dimension of the array should be equal to the number of indices.
Y must be at least 2 dimensional.</p>
</dd>
</dl>
<dl class="simple">
<dt>bool</dt><dd><p>True, if deposited properly. False, otherwise.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="chemml.optimization.ActiveLearning.get_target_layer">
<code class="sig-name descname">get_target_layer</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">X</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.ActiveLearning.get_target_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>The main function to get the latent features from the linear layer of the keras model.</p>
<dl class="simple">
<dt>ndarray</dt><dd><p>The concatenated array of the specified hidden layers by parameter <cite>target_layer</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="chemml.optimization.ActiveLearning.ignore">
<code class="sig-name descname">ignore</code><span class="sig-paren">(</span><em class="sig-param">indices</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.ActiveLearning.ignore" title="Permalink to this definition">¶</a></dt>
<dd><p>If you found out that the experimental setup or computational research on some of the candidates
is not feasible, just pass a list of their indices here and we remove them from the list of queries.</p>
<dl class="simple">
<dt>indices: ndarray or list or tuple</dt><dd><p>A 1D array of all the indices that should be removed from the list of <cite>queries</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="chemml.optimization.ActiveLearning.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">random_state=90</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.ActiveLearning.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>The function to initialize the training and test set for the search.
You can run this function only once before starting the search.</p>
<dl class="simple">
<dt>random_state: int or RandomState, optional (default = 90)</dt><dd><p>The random state will be directly passed to the sklearn.model_selection.ShuffleSplit
extra info at: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn-model-selection-shufflesplit">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn-model-selection-shufflesplit</a></p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>The training set indices (Python 0-index) from the pool of candidates (U).
This is a 1D array.</p>
</dd>
<dt>ndarray</dt><dd><p>The test set indices (Python 0-index) from the pool of candidates (U).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="chemml.optimization.ActiveLearning.random_search">
<code class="sig-name descname">random_search</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">test_type='passive'</em>, <em class="sig-param">scale=True</em>, <em class="sig-param">n_evaluation=10</em>, <em class="sig-param">random_state=90</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.ActiveLearning.random_search" title="Permalink to this definition">¶</a></dt>
<dd><p>This function randomly select same number of data points as the active learning rounds and store the results.</p>
<dl class="simple">
<dt>Y: array-like</dt><dd><p>The 2-dimensional label for all the candidates in the pool. Basically, you won’t run this method unless you have the labels
for all your samples. Otherwise, trust us and perform an active learning search.</p>
</dd>
<dt>test_type: str, optional (default = ‘passive’)</dt><dd><p>The parameter value must be either ‘passive’ or ‘active’.
If passive, the initial randomly selected test set in the initialize method will be used for evaluation.
If active, the current test set of active learning approach will be used for evaluation. Thus, if the test_type in active
learning method is ‘passive’, you should run active and random search back to back and then deposit the data.
This way you make sure both active and random search are tested on the same test sets.</p>
</dd>
<dt>scale: bool or list, optional (default = True)</dt><dd><p>if True, sklearn.preprocessing.StandardScaler will be used to scale X and Y before training.
You can also pass a list of two scaler instances that perform sklearn-style fit_transform and transform methods
for the X and Y, respectively.</p>
</dd>
<dt>n_evaluation: int, optional (default = 3)</dt><dd><p>number of times to repeat training of the model and evaluation on test set.</p>
</dd>
<dt>random_state: int or RandomState, optional (default = 90)</dt><dd><p>The random state will be directly passed to the sklearn.model_selection methods.
Please find additional info at: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html</a></p>
</dd>
<dt>kwargs</dt><dd><p>Any argument (except input data) that should be passed to the model’s fit method.</p>
</dd>
</dl>
<dl class="simple">
<dt>random_results: pandas dataframe</dt><dd><p>The results from the random sampling to provide the baseline for your active learning search.
You need to</p>
</dd>
</dl>
<blockquote>
<div><ul class="simple">
<li><p>This method replicate the active learning training size with random sampling approach. Thus, you can run</p></li>
</ul>
<p>this function only if the results is not empty, i.e., you have run the active learning search at least once.</p>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="chemml.optimization.ActiveLearning.search">
<code class="sig-name descname">search</code><span class="sig-paren">(</span><em class="sig-param">n_evaluation=3</em>, <em class="sig-param">ensemble='bootstrap'</em>, <em class="sig-param">n_ensemble=4</em>, <em class="sig-param">normalize_input=True</em>, <em class="sig-param">normalize_internal=False</em>, <em class="sig-param">random_state=90</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.ActiveLearning.search" title="Permalink to this definition">¶</a></dt>
<dd><p>The main function to start or continue an active learning search.
The bootstrap approach is used to generate an ensemble of models that estimate the prediction
distribution of the candidates’ labels.</p>
<dl>
<dt>n_evaluation: int, optional (default = 3)</dt><dd><p>number of times to repeat training of the model and evaluation on test set.</p>
</dd>
<dt>ensemble: str, optional (default = ‘bootstrap’)</dt><dd><dl class="simple">
<dt>The sampling method to create n ensembles and estimate the predictive distributions.</dt><dd><ul class="simple">
<li><p>‘bootstrap’: standard bootstrap method (random choice with replacement)</p></li>
<li><p>‘shuffle’ : sklearn.model_selection.ShuffleSplit</p></li>
<li><p>‘kfold’ : sklearn.model_selection.KFold</p></li>
</ul>
</dd>
</dl>
<p>The ‘shuffle’ and ‘kfold’ methods draw samples that are smaller than training set.</p>
</dd>
<dt>n_ensemble: int, optional (default = 5)</dt><dd><p>The size of the ensemble based on bootstrapping approach.</p>
</dd>
<dt>normalize_input: bool or list, optional (default = True)</dt><dd><p>if True, sklearn.preprocessing.StandardScaler will be used to normalize X and Y before training.
You can also pass a list of two scaler instances that perform sklearn-style fit_transform and transform methods
for the X and Y, respectively.</p>
</dd>
<dt>normalize_internal: bool, optional (default = False)</dt><dd><p>if True, the internal variables for estimation of gradients will be normalized.</p>
</dd>
<dt>random_state: int or RandomState, optional (default = 90)</dt><dd><p>The random state will be directly passed to the sklearn.model_selection.KFold or ShuffleSplit
Additional info at: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html</a></p>
</dd>
<dt>kwargs</dt><dd><p>Any argument (except input data) that should be passed to the model’s fit method.</p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>The training set indices (Python 0-index) from the pool of candidates (U).
This is a 1D array.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="chemml.optimization.ActiveLearning.visualize">
<code class="sig-name descname">visualize</code><span class="sig-paren">(</span><em class="sig-param">Y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#chemml.optimization.ActiveLearning.visualize" title="Permalink to this definition">¶</a></dt>
<dd><p>This function plot distribution of labels and principal components of the features for the last round of the
active learning search.
Note that this function uses the prediction values in the attribute <cite>Y_pred</cite>. This attribute will be updated after
each round of search. Thus, we recommend you run <cite>visualize</cite> right after each call of search method to get a trajectory
of the active learning process.</p>
<dl class="simple">
<dt>Y: array-like, optional (default = None)</dt><dd><p>The 2-dimensional label for all the candidates in the pool (in case you have them!!!).
If you have all the labels, we will be able to produce additional cool visualizations.</p>
</dd>
</dl>
<dl class="simple">
<dt>list</dt><dd><p>A list of matplotlib.figure.Figure or tuples. This object contains information about the plot</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="chemml.visualization.html" class="btn btn-neutral float-right" title="Visualization module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="chemml.models.html" class="btn btn-neutral float-left" title="Models module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014-2018 Johannes Hachmann, Mojtaba Haghighatlari

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>